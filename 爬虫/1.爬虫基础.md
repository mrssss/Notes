# 什么是爬虫

* 定义
> 网络爬虫是按照一定的规则，自动地抓取万维网信息的程序或者脚本。
> 用于方便用户下载。
> 依靠程序大规模的获取你说需要的网络信息

# 为什么推荐使用Python写爬虫

* 上手容易。
* 对文本处理简单。
* google用Python写爬虫，所以可以使用的库比较多。
* 开源
* 可跨平台
* 面向对象
* 框架和库支持丰富，有大量的历史积累
* 和其他语言交互比较好
* 开发效率高

# 为什么要学爬虫

* 爬虫是信息收集的一种手段
* 是大数据的支持技术
* 大量数据是做更正确的决策的基础
* 爬虫不仅是一种技术上的东西，在生活中也很有用处

# http简介

* http：超文本连接
* URI：Uniform resource identifer
* URL：Uniform resource locator
* URI和URL的区别：URI强调资源，URL强调资源的位置
* 常用请求类型

|名称|作用|
|:-:|:-:|
|OPTIONS|返回服务器对特定资源所支持的http请求方法|
|HEAD|向服务器索要与get请求相一致的响应，只不过响应体将不会被返回|
|GET|向特定资源发出请求|
|PUT|向特定资源位置上传其最新内容|
|POST|向指定资源提交数据进行处理请求|
|DELETE|请求服务器删除指定URI所标识的资源|
|PATCH|用来将局部修改应用于某一资源|

> GET是获取文件，HEAD是查询文件是否存在。
> 上传文件使用PUT，上传表单之类的数据使用POST。

> 爬虫是向服务器发送http请求来获取相应的数据

* 常见http状态码

|状态码|含义|
|:-:|:-:|
|200/OK|请求成功|
|201/Created|请求已被实现，且一个新资源根据请求被建立，URI跟随Location头信息返回|
|202/Accepted|服务器已接受请求，但尚未处理|
|400/Bad Request|请求无法被服务器理解|
|401/Unauthorized|当前请求需要用户验证|
|403/Forbidden|服务器已理解请求，但拒绝执行|
|404/Not Found|没有找到资源|



# HTML/XML/Json简介

* HTML：超文本 Hypertext Markup Language
* HTML不是编程语言，而是一种标记语言
* HTML使用标签来描述网页
* HTML是XML的一个子集
* markdown也是一种标记语言
* DOM文档模型，就是一个树形结构
* Json可以看成简化的XML使用
* Json推荐使用小数据
* Json使用起来比较友好

# 爬虫框架介绍

## 爬虫工作流程

* 将种子URL放入队列
* 从队列中获取URL，抓取内容
* 解析抓取内容，将需要进一步抓取的URL放入工作队列，存储解析后的内容

## 抓取策略

* 深度优先
* 广度优先
* PageRank
* 大站优先策略

## 如何去重

* Hash表
* 布隆（bloom）过滤器

# robots规范和爬虫原则

> 网络爬虫排除标准
> 网站通过Robots协议告诉搜索引擎哪些页面可以抓取，哪些页面不能抓取。